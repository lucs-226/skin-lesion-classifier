\section{Experiments and Results}

\subsection{Training Dynamics}
The model was implemented in PyTorch and trained on a GPU-accelerated environment for 20 epochs. We utilized the \textbf{AdamW} optimizer, decoupled from weight decay ($1e-4$), to enhance generalization performance compared to standard Adam. The learning rate was initialized at $3\times10^{-4}$ and managed via a \textbf{Cosine Annealing} scheduler, which smoothly decays the rate to near-zero over the course of training. This scheduling helps the model settle into a flat local minimum, improving inference robustness. The batch size was set to 32 to accommodate the $300\times300$ resolution within memory constraints.

\subsection{Quantitative Analysis}
We evaluated the model on a held-out test set comprising 10\% of the original dataset. Table \ref{tab:results} summarizes the per-class performance.

The introduction of Focal Loss yielded a tangible improvement in sensitivity for malignant classes. Specifically, the model achieves a Recall of \textbf{0.68} for Melanoma (Mel) and \textbf{0.75} for Basal Cell Carcinoma (BCC). This is a critical clinical metric, as it indicates a reduced rate of false negatives for dangerous lesions. The high precision on the Nevus class (0.92) confirms that the weighted strategy successfully mitigated the class imbalance without collapsing the model into predicting only the majority class.

\begin{table}[h]
\centering
\resizebox{\columnwidth}{!}{
\begin{tabular}{l|ccc}
\toprule
\textbf{Class} & \textbf{Precision} & \textbf{Recall} & \textbf{F1-Score} \\
\midrule
Actinic Keratoses (akiec) & 0.58 & 0.62 & 0.60 \\
Basal Cell Carcinoma (bcc) & 0.71 & 0.75 & 0.73 \\
Benign Keratosis (bkl) & 0.65 & 0.60 & 0.62 \\
Dermatofibroma (df) & 0.70 & 0.65 & 0.67 \\
Melanoma (mel) & 0.62 & 0.68 & 0.65 \\
Nevus (nv) & 0.92 & 0.90 & 0.91 \\
Vascular (vasc) & 0.75 & 0.80 & 0.77 \\
\bottomrule
\end{tabular}
}
\caption{Classification metrics on the external validation set. The proposed Full Fine-Tuning + Focal Loss strategy effectively balances the trade-off between precision and recall.}
\label{tab:results}
\end{table}

\section{Conclusion}
The EfficientNet-B3 architecture provides a robust baseline for dermoscopic classification. By combining a Full Fine-Tuning strategy with a custom Focal Loss, we addressed the inherent class imbalance of the HAM10000 dataset. Future work will focus on integrating Test-Time Augmentation (TTA) and ensemble methods to further push the boundaries of sensitivity on ambiguous pigmented lesions.
