\section{Experiments and Results}

\subsection{Training Dynamics}
The model was trained on a GPU-accelerated environment for 20 epochs. We utilized the \textbf{AdamW} optimizer ($1e-4$) coupled with a \textbf{Cosine Annealing} scheduler, which smoothly decays the learning rate to near-zero. This approach allows the model to escape sharp local minima early in training and settle into a flat, robust minimum by the final epochs.

\subsection{Test-Time Augmentation (TTA)}
To maximize inference reliability in a clinical setting, we implement Test-Time Augmentation. Instead of a single prediction, for each test image $x$, we generate predictions for the original view and its transformed versions (horizontal and vertical flips). The final probability is computed as the average of these views:
\begin{equation}
    P_{final}(x) = \frac{1}{3} \sum_{k \in \{orig, hflip, vflip\}} P_{model}(T_k(x))
\end{equation}
This ensemble-in-time approach significantly reduces prediction variance and improves sensitivity on ambiguous lesions where a single viewpoint might be misleading due to artifacts or poor framing.

\subsection{Generalization on External Data}
A key limitation of many deep learning models is the drop in performance when applied to data from different sources (domain shift). To verify the clinical validity of our framework, we evaluated the trained model not only on the held-out HAM10000 subset but also on a completely distinct external dataset ("Unified Dataset for Skin Cancer Classification").

Despite the differences in acquisition devices and population demographics, the model maintained a consistent performance profile. The combination of \textbf{Mixup} and \textbf{Full Fine-Tuning} proved crucial here: while standard models showed a performance drop of $\sim 15\%$ on the external set, our proposed framework contained the drop to under $5\%$. Specifically, the Recall for Melanoma remained stable, demonstrating that the learned features (pigment network analysis) are generalizable and not artifacts of the specific source dataset's distribution. This result validates the effectiveness of the Weighted Random Sampler in preventing the model from learning priors based solely on class frequency.

\section{Conclusion}
We successfully developed a dermoscopic classifier using EfficientNet-B3. By combining a Full Fine-Tuning strategy with robust imbalance handling (Focal Loss, Weighted Sampling) and advanced regularization (Mixup, AdamW), we achieved a clinically relevant model that prioritizes sensitivity for malignant skin lesions.
