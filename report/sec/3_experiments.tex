\section{Experiments and Results}

\subsection{Training Dynamics}
The model was trained on a GPU-accelerated environment for 15 epochs. We utilized the \textbf{AdamW} optimizer ($3e-4$) coupled with a \textbf{Cosine Annealing} scheduler, which smoothly decays the learning rate to near-zero. This approach allows the model to escape sharp local minima early in training and settle into a flat, robust minimum by the final epochs.

\subsection{Test-Time Augmentation (TTA)}
To maximize inference reliability in a clinical setting, we implement Test-Time Augmentation. Instead of a single prediction, for each test image $x$, we generate predictions for the original view and its transformed versions (horizontal and vertical flips). The final probability is computed as the average of these views:
\begin{equation}
    P_{final}(x) = \frac{1}{3} \sum_{k \in \{orig, hflip, vflip\}} P_{model}(T_k(x))
\end{equation}
This ensemble-in-time approach significantly reduces prediction variance and improves sensitivity on ambiguous lesions where a single viewpoint might be misleading due to artifacts or poor framing.

\subsection{Generalization and Domain Shift Analysis}
A key challenge in medical imaging is the "Domain Shift" phenomenon, where the statistical distribution of testing data differs significantly from the training data. To assess this, we evaluated the model on the external "Unified Dataset for Skin Cancer Classification".

While the model maintained satisfactory performance on the majority class ('Nevus'), demonstrating that certain textural features are robust across domains, the results on malignant categories were disappointing. The domain gap—likely caused by distinct differences in dermatoscopic hardware, illumination conditions, and patient demographics—severely impacted the model's reliability.
Crucially, we observed a dangerous increase in the False Negative rate: approximately \textbf{47\%} of actual malignant lesions were misclassified as benign. This alarming error rate highlights that the deep features learned from the HAM10000 source domain, while discriminative within that specific distribution, fail to generalize when lighting and color histograms shift. The model effectively overfitted to the acquisition characteristics (biases) of the source dataset rather than learning purely semantic lesion morphology.

\section{Conclusion}
Our experimental results on the HAM10000 benchmark place our solution among the top-performing implementations available on public Kaggle notebooks. In this work, we presented a dermoscopic classification framework based on EfficientNet-B3. Within the boundaries of the HAM10000 benchmark, our proposed strategy of Full Fine-Tuning combined with a custom Focal Loss and Weighted Random Sampling proved highly effective. The model successfully navigated the severe class imbalance, achieving a strong trade-off between precision and recall, and demonstrating excellent convergence properties driven by the AdamW optimizer.

However, the external validation exposed significant criticalities regarding the model's robustness in real-world, multi-center scenarios. The substantial performance drop on the external dataset, characterized by the inability to reliably detect malignant cases outside the training distribution, underscores the severity of the Domain Shift problem in automated diagnosis. The model relies too heavily on source-specific color correlations which do not hold across different acquisition protocols.

To bridge this gap and move towards a clinically deployable tool, future research must prioritize generalization over simple in-domain accuracy. Key strategies to combat Domain Shift include:
\begin{itemize}
    \item \textbf{Data Diversity:} Incorporating multi-source datasets during training is essential to expose the model to a wider variety of acquisition devices and skin types, preventing it from memorizing specific camera artifacts.
    \item \textbf{Advanced Normalization:} Implementing rigorous color constancy algorithms (e.g., Gray World, Stain Normalization) to standardize the input color space and align the histograms of different domains before processing.
    \item \textbf{Stronger Augmentation:} Exploring domain-randomization techniques or leveraging Generative Adversarial Networks (GANs) to synthesize diverse training samples. This would force the model to learn shape-invariant features that are independent of chromatic variations.
\end{itemize}
Only by addressing these generalization challenges we can achieve a high performing and clinically useful model.

\clearpage

\section{Author Contributions}
The development of this framework was a collaborative effort, with specific responsibilities divided as follows:

\begin{itemize}
    \item \textbf{Luca Santonocito:} Engineered the training strategy, implementing the Weighted Random Sampler and the custom Focal Loss. He also configured the optimization logic (AdamW, Scheduler) and the Test-Time Augmentation (TTA) module.
    \item \textbf{Sara Maria Secreti:} Designed the regularization pipeline by implementing Mixup and Random Erasing techniques. She was responsible for selecting the EfficientNet-B3 architecture and performing the critical validation on the external dataset.
    \item \textbf{Mehmet Sener:} Conducted the Exploratory Data Analysis (EDA) and statistical profiling of the HAM10000 dataset, identifying key distribution characteristics.
\end{itemize}
    
   
